{
  "name": "LLM Model Selection Feature (v0.8.0)",
  "baseBranch": "main",
  "targetBranch": "feature/llm-model-selection",
  "maxParallel": 3,
  "cleanUpSuccessfulWork": false,
  "jobs": [],
  "groups": [
    {
      "name": "phase1-discovery",
      "jobs": [
        {
          "producer_id": "model-discovery-module",
          "name": "Create Model Discovery Module",
          "task": "Create src/agent/modelDiscovery.ts with dynamic model extraction from Copilot CLI",
          "dependencies": [],
          "work": {
            "type": "agent",
            "model": "claude-opus-4.5",
            "instructions": "# Create Model Discovery Module\n\n## Objective\nCreate `src/agent/modelDiscovery.ts` that dynamically discovers available models from `copilot --help` output.\n\n## Requirements\n\n### Types\n```typescript\nexport interface ModelInfo {\n  id: string;\n  vendor: 'openai' | 'anthropic' | 'google' | 'unknown';\n  family: string;\n  tier: 'fast' | 'standard' | 'premium';\n}\n\nexport interface ModelDiscoveryResult {\n  models: ModelInfo[];\n  rawChoices: string[];\n  discoveredAt: number;\n  cliVersion?: string;\n}\n```\n\n### Functions to Implement\n1. `discoverAvailableModels()` - Run `copilot --help`, parse `--model` choices\n2. `getCachedModels()` - Return cached results if fresh (1 hour TTL)\n3. `refreshModelCache()` - Force re-discovery\n4. `isValidModel(modelId)` - Validate against discovered models\n5. `suggestModel(taskType)` - Suggest model based on task complexity\n6. `classifyModel(id)` - Determine vendor/tier from model ID\n\n### Parsing Strategy\nThe `--help` output contains:\n```\n--model <model>  Set the AI model to use (choices: \"claude-sonnet-4.5\", \"gpt-5\", ...)\n```\n\nUse regex: `/--model\\s+<\\w+>\\s+.*?\\(choices:\\s*([^)]+)\\)/i`\n\n### Vendor Classification\n- `claude-*` → anthropic\n- `gpt-*` → openai\n- `gemini-*` → google\n\n### Tier Classification\n- Contains `mini` or `haiku` → fast\n- Contains `opus` or `max` → premium\n- Default → standard\n\n### Error Handling\n- If Copilot CLI not available, return empty result with error flag\n- If parsing fails, log warning and return empty result\n- Cache failures for 5 minutes to avoid spam\n\n### Testing\nAdd unit tests in `src/test/suite/agent/modelDiscovery.test.ts`"
          },
          "postchecks": "npm run compile"
        },
        {
          "producer_id": "model-discovery-tests",
          "name": "Write Model Discovery Tests",
          "task": "Create comprehensive tests for model discovery",
          "dependencies": ["model-discovery-module"],
          "work": {
            "type": "agent",
            "model": "gpt-5",
            "instructions": "# Create Model Discovery Tests\n\n## File\n`src/test/suite/agent/modelDiscovery.test.ts`\n\n## Test Cases\n\n1. **Parse valid help output** - Mock copilot --help with known models\n2. **Handle missing --model flag** - Graceful fallback\n3. **Classify vendors correctly** - claude→anthropic, gpt→openai, gemini→google\n4. **Classify tiers correctly** - mini→fast, opus→premium\n5. **Cache TTL works** - Results cached for 1 hour\n6. **suggestModel returns appropriate tier** - planning→premium, simple→fast\n7. **isValidModel validates against cache** - True for known, false for unknown\n\n## Mock Strategy\nUse sinon to stub `child_process.exec` or create mock help output strings.\n\n## Example Mock Output\n```\n--model <model>  Set the AI model to use (choices: \"gpt-5\", \"gpt-5-mini\", \"claude-opus-4.5\")\n```"
          },
          "postchecks": "npm test -- --grep \"modelDiscovery\""
        }
      ]
    },
    {
      "name": "phase2-wiring",
      "jobs": [
        {
          "producer_id": "agent-delegator-model",
          "name": "Wire Model to Agent Delegator",
          "task": "Update AgentDelegator to pass --model flag to Copilot CLI",
          "dependencies": ["phase1-discovery/model-discovery-module"],
          "work": {
            "type": "agent",
            "model": "gpt-5",
            "instructions": "# Update AgentDelegator for Model Selection\n\n## File\n`src/agent/agentDelegator.ts`\n\n## Changes\n\n### 1. Update DelegateOptions interface\nAdd `model?: string` field (if not already present).\n\n### 2. Update delegateViaCopilot method\nWhen building `copilotCmd`, add model flag:\n```typescript\nif (options.model) {\n  copilotCmd += ` --model ${options.model}`;\n}\n```\n\n### 3. Validate model before use\nImport `isValidModel` from modelDiscovery and warn if invalid:\n```typescript\nif (options.model && !isValidModel(options.model)) {\n  this.logger.log(`[${label}] Warning: Model '${options.model}' not in discovered models`);\n}\n```\n\n## Location\nThe copilotCmd is built around line 236. Add the --model flag after other flags."
          },
          "postchecks": "npm run compile"
        },
        {
          "producer_id": "executor-verify",
          "name": "Verify Executor Passes Model",
          "task": "Ensure executor passes model from AgentSpec to delegator",
          "dependencies": ["agent-delegator-model"],
          "work": {
            "type": "agent",
            "model": "gpt-5-mini",
            "instructions": "# Verify Executor Model Passthrough\n\n## File\n`src/plan/executor.ts`\n\n## Verification\nIn the `runAgent` method (around line 835), verify that `spec.model` is passed to the delegator.\n\nThe call should look like:\n```typescript\nconst result = await this.agentDelegator.delegate({\n  task: spec.instructions,\n  model: spec.model,  // ← Verify this exists\n  // ...\n});\n```\n\nIf not present, add it.\n\n## Also\nLog the model being used in the execution logs:\n```typescript\nif (spec.model) {\n  this.logInfo(executionKey, 'work', `Using model: ${spec.model}`);\n}\n```"
          },
          "postchecks": "npm run compile"
        }
      ]
    },
    {
      "name": "phase3-mcp-schema",
      "jobs": [
        {
          "producer_id": "mcp-dynamic-models",
          "name": "Dynamic Model Enum in MCP Schema",
          "task": "Update MCP tool definitions to include discovered models",
          "dependencies": ["phase1-discovery/model-discovery-module"],
          "work": {
            "type": "agent",
            "model": "claude-opus-4.5",
            "instructions": "# Add Dynamic Model Enum to MCP Tools\n\n## Files\n- `src/mcp/tools/planTools.ts`\n- `src/mcp/mcpRegistration.ts`\n\n## Changes to planTools.ts\n\n### 1. Import model discovery\n```typescript\nimport { discoverAvailableModels, ModelDiscoveryResult } from '../../agent/modelDiscovery';\n```\n\n### 2. Make getPlanToolDefinitions async\nChange signature to:\n```typescript\nexport async function getPlanToolDefinitions(): Promise<McpTool[]>\n```\n\n### 3. Discover models at the start\n```typescript\nconst modelResult = await discoverAvailableModels();\nconst modelEnum = modelResult.rawChoices.length > 0 \n  ? modelResult.rawChoices \n  : ['gpt-5', 'claude-sonnet-4.5'];  // Fallback defaults\n```\n\n### 4. Add model to AgentSpec schema in work property\nIn the job work property description, add:\n- List of available models\n- Model property with enum constraint\n\nExample in the nested agent object schema:\n```typescript\nmodel: {\n  type: 'string',\n  enum: modelEnum,\n  description: 'LLM model to use. Fast (mini/haiku) for simple tasks, premium (opus) for complex reasoning.'\n}\n```\n\n### 5. Update work description\nAdd examples showing model selection in the description string.\n\n## Changes to mcpRegistration.ts\nMake the registration async to support async getPlanToolDefinitions."
          },
          "postchecks": "npm run compile"
        },
        {
          "producer_id": "refresh-models-command",
          "name": "Add Refresh Models Command",
          "task": "Add VS Code command to refresh model cache",
          "dependencies": ["mcp-dynamic-models"],
          "work": {
            "type": "agent",
            "model": "gpt-5-mini",
            "instructions": "# Add Refresh Models Command\n\n## File\n`src/commands/utilityCommands.ts`\n\n## Add Command\n```typescript\nvscode.commands.registerCommand('copilotOrchestrator.refreshModels', async () => {\n  const { refreshModelCache } = await import('../agent/modelDiscovery');\n  const result = await refreshModelCache();\n  if (result.models.length > 0) {\n    vscode.window.showInformationMessage(\n      `Discovered ${result.models.length} models from Copilot CLI`\n    );\n  } else {\n    vscode.window.showWarningMessage(\n      'Could not discover models. Is Copilot CLI installed?'\n    );\n  }\n});\n```\n\n## Register in package.json\nAdd to `contributes.commands`:\n```json\n{\n  \"command\": \"copilotOrchestrator.refreshModels\",\n  \"title\": \"Copilot Orchestrator: Refresh Available Models\"\n}\n```"
          },
          "postchecks": "npm run compile"
        }
      ]
    },
    {
      "name": "phase4-token-tracking",
      "jobs": [
        {
          "producer_id": "token-types",
          "name": "Add Token Usage Types",
          "task": "Add TokenUsage and AgentExecutionMetrics types",
          "dependencies": ["phase2-wiring/executor-verify"],
          "work": {
            "type": "agent",
            "model": "gpt-5-mini",
            "instructions": "# Add Token Usage Types\n\n## File\n`src/plan/types/specs.ts`\n\n## Add Types\n```typescript\n/**\n * Token usage statistics from an LLM invocation.\n */\nexport interface TokenUsage {\n  inputTokens: number;\n  outputTokens: number;\n  totalTokens: number;\n  model: string;\n  estimatedCostUsd?: number;\n}\n\n/**\n * Execution metrics for agent work.\n */\nexport interface AgentExecutionMetrics {\n  tokenUsage?: TokenUsage;\n  durationMs: number;\n  turns?: number;\n  toolCalls?: number;\n}\n```\n\n## Export\nEnsure types are exported from `src/plan/types/index.ts`"
          },
          "postchecks": "npm run compile"
        },
        {
          "producer_id": "token-extraction",
          "name": "Extract Tokens from Copilot Logs",
          "task": "Parse Copilot CLI logs to extract token usage",
          "dependencies": ["token-types"],
          "work": {
            "type": "agent",
            "model": "claude-sonnet-4.5",
            "instructions": "# Extract Token Usage from Copilot Logs\n\n## File\n`src/agent/agentDelegator.ts`\n\n## Add Method\n```typescript\n/**\n * Extract token usage from Copilot CLI log files.\n * \n * Looks for patterns like:\n * - `Usage: { prompt_tokens: X, completion_tokens: Y }`\n * - `Tokens: input=X, output=Y`\n * - JSON objects with token counts\n */\nprivate async extractTokenUsage(logDir: string, model?: string): Promise<TokenUsage | undefined>\n```\n\n## Implementation\n1. Find most recent log file in logDir\n2. Read and parse for token patterns\n3. Sum all token usages if multiple calls\n4. Return structured TokenUsage\n\n## Patterns to Search\n```typescript\nconst patterns = [\n  /prompt_tokens[\"']?:\\s*(\\d+)/gi,\n  /completion_tokens[\"']?:\\s*(\\d+)/gi,\n  /input[_\\s]tokens?[\"']?:\\s*(\\d+)/gi,\n  /output[_\\s]tokens?[\"']?:\\s*(\\d+)/gi,\n];\n```\n\n## Update DelegateResult\nAdd `tokenUsage?: TokenUsage` to DelegateResult interface.\n\n## Call After Completion\nIn delegateViaCopilot, after process exits, call extractTokenUsage and include in result."
          },
          "postchecks": "npm run compile"
        },
        {
          "producer_id": "store-metrics",
          "name": "Store Metrics in Node State",
          "task": "Add metrics field to NodeExecutionState and populate it",
          "dependencies": ["token-extraction"],
          "work": {
            "type": "agent",
            "model": "gpt-5",
            "instructions": "# Store Metrics in Node Execution State\n\n## Files\n- `src/plan/types/plan.ts` or `src/plan/types/nodes.ts`\n- `src/plan/executor.ts`\n\n## Add Field\nIn NodeExecutionState (or equivalent):\n```typescript\nmetrics?: AgentExecutionMetrics;\n```\n\n## Populate in Executor\nIn the `runAgent` method, capture and store metrics:\n```typescript\nif (result.tokenUsage) {\n  // Store in execution state or return with result\n}\n```\n\n## Persist Metrics\nEnsure metrics are included in plan serialization so they survive reload."
          },
          "postchecks": "npm run compile"
        }
      ]
    },
    {
      "name": "phase5-ui",
      "jobs": [
        {
          "producer_id": "node-detail-tokens",
          "name": "Show Tokens in Node Detail Panel",
          "task": "Display token usage in node detail panel",
          "dependencies": ["phase4-token-tracking/store-metrics"],
          "work": {
            "type": "agent",
            "model": "gpt-5",
            "instructions": "# Display Token Usage in Node Detail Panel\n\n## File\n`src/ui/panels/nodeDetailPanel.ts`\n\n## Add Section\nAfter the existing work info section, add a metrics section:\n```html\n<div class=\"metrics-section\">\n  <h4>Execution Metrics</h4>\n  <div class=\"metric-row\">\n    <span class=\"metric-label\">Model:</span>\n    <span class=\"metric-value\">${metrics.tokenUsage?.model || 'N/A'}</span>\n  </div>\n  <div class=\"metric-row\">\n    <span class=\"metric-label\">Tokens:</span>\n    <span class=\"metric-value\">\n      ${metrics.tokenUsage?.inputTokens || 0} in / \n      ${metrics.tokenUsage?.outputTokens || 0} out\n    </span>\n  </div>\n  <div class=\"metric-row\">\n    <span class=\"metric-label\">Est. Cost:</span>\n    <span class=\"metric-value\">\n      ${metrics.tokenUsage?.estimatedCostUsd?.toFixed(4) || 'N/A'}\n    </span>\n  </div>\n</div>\n```\n\n## CSS\nAdd styles for metrics display."
          },
          "postchecks": "npm run compile"
        },
        {
          "producer_id": "plan-detail-summary",
          "name": "Add Token Summary to Plan Detail",
          "task": "Show aggregate token usage in plan detail panel",
          "dependencies": ["node-detail-tokens"],
          "work": {
            "type": "agent",
            "model": "gpt-5",
            "instructions": "# Add Token Summary to Plan Detail Panel\n\n## File\n`src/ui/panels/planDetailPanel.ts`\n\n## Add Summary Section\nAfter the job list, add a collapsible token summary:\n```html\n<details class=\"token-summary\" open>\n  <summary>Token Usage Summary</summary>\n  <table class=\"token-table\">\n    <thead>\n      <tr>\n        <th>Job</th>\n        <th>Model</th>\n        <th>Input</th>\n        <th>Output</th>\n        <th>Total</th>\n        <th>Cost</th>\n      </tr>\n    </thead>\n    <tbody>\n      <!-- Per-job rows -->\n    </tbody>\n    <tfoot>\n      <tr class=\"total-row\">\n        <td colspan=\"4\">Total</td>\n        <td>${totalTokens}</td>\n        <td>${totalCost}</td>\n      </tr>\n    </tfoot>\n  </table>\n</details>\n```\n\n## Compute Totals\n```typescript\nfunction computeTokenSummary(plan: PlanInstance): TokenSummary {\n  const jobs = plan.nodes.filter(n => n.state?.metrics?.tokenUsage);\n  return {\n    totalInput: jobs.reduce((s, j) => s + (j.state.metrics.tokenUsage.inputTokens || 0), 0),\n    totalOutput: jobs.reduce((s, j) => s + (j.state.metrics.tokenUsage.outputTokens || 0), 0),\n    totalCost: jobs.reduce((s, j) => s + (j.state.metrics.tokenUsage.estimatedCostUsd || 0), 0),\n  };\n}\n```"
          },
          "postchecks": "npm run compile"
        }
      ]
    },
    {
      "name": "phase6-docs",
      "jobs": [
        {
          "producer_id": "update-readme",
          "name": "Update README with Model Selection",
          "task": "Document model selection feature in README",
          "dependencies": ["phase5-ui/plan-detail-summary", "phase3-mcp-schema/mcp-dynamic-models"],
          "work": {
            "type": "agent",
            "model": "gpt-5-mini",
            "instructions": "# Update README for Model Selection\n\n## File\n`README.md`\n\n## Add Section\nAfter the MCP tools section, add:\n\n### LLM Model Selection\n\nThe orchestrator supports specifying which LLM model to use for agent tasks. Models are automatically discovered from your installed Copilot CLI.\n\n**Example:**\n```json\n{\n  \"type\": \"agent\",\n  \"instructions\": \"Design the API architecture\",\n  \"model\": \"claude-opus-4.5\"\n}\n```\n\n**Model Tiers:**\n- **Fast** (mini, haiku): Simple tasks, code fixes, formatting\n- **Standard** (sonnet, gpt-5): General coding, implementation\n- **Premium** (opus, max): Complex reasoning, architecture, planning\n\n**Token Tracking:**\nThe plan detail panel shows token usage and estimated costs for each job.\n\n**Refresh Models:**\nRun `Copilot Orchestrator: Refresh Available Models` to update the available model list after updating Copilot CLI."
          },
          "postchecks": "npm run compile"
        },
        {
          "producer_id": "update-architecture",
          "name": "Update Architecture Docs",
          "task": "Document model discovery and token tracking in ARCHITECTURE.md",
          "dependencies": ["update-readme"],
          "work": {
            "type": "agent",
            "model": "gpt-5-mini",
            "instructions": "# Update ARCHITECTURE.md\n\n## File\n`docs/ARCHITECTURE.md`\n\n## Add Section: Model Discovery\n\n### Dynamic Model Discovery\n\nThe orchestrator discovers available LLM models at runtime by parsing `copilot --help` output. This ensures compatibility as Copilot CLI evolves.\n\n**Flow:**\n1. On extension activation, `discoverAvailableModels()` runs\n2. Parses `--model` choices from CLI help\n3. Caches results for 1 hour\n4. MCP tool schemas include discovered models as enum\n\n**Classification:**\n- Vendor: claude→anthropic, gpt→openai, gemini→google\n- Tier: mini/haiku→fast, opus/max→premium, default→standard\n\n## Add Section: Token Tracking\n\n### Token Usage Tracking\n\nAfter each agent job completes, the orchestrator extracts token usage from Copilot CLI logs.\n\n**Extracted Metrics:**\n- Input tokens\n- Output tokens  \n- Model used\n- Estimated cost (based on public pricing)\n\n**Storage:**\nMetrics are stored in `NodeExecutionState.metrics` and persisted with the plan."
          }
        }
      ]
    },
    {
      "name": "phase7-validation",
      "jobs": [
        {
          "producer_id": "integration-tests",
          "name": "Add Integration Tests",
          "task": "Create integration tests for model selection feature",
          "dependencies": ["phase6-docs/update-architecture"],
          "work": {
            "type": "agent",
            "model": "gpt-5",
            "instructions": "# Create Integration Tests\n\n## File\n`src/test/suite/integration/modelSelection.test.ts`\n\n## Test Cases\n\n1. **MCP schema includes models** - Verify getPlanToolDefinitions returns model enum\n2. **Executor passes model to delegator** - Mock delegator, verify model received\n3. **Token extraction from mock logs** - Test log parsing with sample data\n4. **Plan serialization includes metrics** - Serialize/deserialize with token data\n5. **Invalid model logs warning** - Verify warning when unknown model used\n\n## Mocking\nUse sinon to mock:\n- `child_process.exec` for copilot --help\n- File system for log reading\n- AgentDelegator for CLI invocation"
          },
          "postchecks": "npm test"
        },
        {
          "producer_id": "final-validation",
          "name": "Final Compilation and Lint",
          "task": "Ensure all code compiles and passes lint",
          "dependencies": ["integration-tests"],
          "work": {
            "type": "shell",
            "command": "npm run compile && npm run lint"
          },
          "postchecks": "npm test"
        }
      ]
    }
  ]
}
